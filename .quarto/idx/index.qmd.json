{"title":"CASA00025 KI 不吃香菜","markdown":{"headingText":"CASA00025 KI 不吃香菜","containsRefs":false,"markdown":"\n## Project Summary \n\nThis application is based on remote sensing technology and machine learning algorithms to assess vegetation cover changes in Gaza during the Palestinian-Israeli conflict. Based on **Sentinel-2** satellite data and the Google Earth Engine platform, the application adopts an automated image preprocessing process (including image extraction, image synthesis, and masking) and utilizes the Random Forest algorithm to develop a classifier to distinguish between three different types of land cover: vegetation, bare land, and urban areas. The project aims to reveal changes in vegetation cover in the Gaza by generating and comparing land cover classification maps before and after the conflict, thereby providing clear evidence to assess the ongoing humanitarian crisis and urban destruction in the Gaza area.\n\n### Problem Statement \n\n**Challenges in Monitoring Vegetation Cover**:\n\nDue to the ongoing conflict in the Gaza area, ground access is extremely limited, making traditional surveying methods unfeasible and accurate information on vegetation status and changes unattainable. This project utilize remote sensing technology and machine learning methods to provide a safe and effective way to monitor vegetation cover changes from a distance, thus solving the challenges of on-site measurement.\n\n**Humanitarian Crisis and Food Dependency in Gaza**:\n\nGaza is one of the most densely populated areas in the world and faces chronic food shortages, heavily relying on international aid. The escalation of the Israel-Palestine conflict has led to the severance of aid supply channels, further increasing the local population's dependency on limited arable land resources. In this context, remote sensing data analysis can effectively assess the impact of the conflict on agricultural land, thereby quantifying the severity of the humanitarian crisis.\n\n\n### End User \n\n**International Aid and Humanitarian Organizations**:\n\nHumanitarian organizations require accurate data to assess the impact of conflicts on local ecology and agricultural productivity, to optimize their aid plans and resource allocation. The remote sensing analysis provided by this project can guide them in formulating more effective rescue and assistance strategies during emergencies.\n\n**Regional Research Scholars**:\n\nFor the Gaza region, which relies heavily on agricultural production, understanding changes in vegetation cover is crucial for adjusting agricultural production plans and farming methods. The results of this project can aid researchers studying the food structure of this region in predicting yield changes and providing sound advice to address Gaza's food shortage issues.\n\n**Public and Media**:\n\nThe results processed through professional technical methods can be visually presented to the public and media, thereby drawing broader attention to the ongoing humanitarian crisis in the Gaza area through more extensive channels.\n\n\n### Data\n\nThis software utilizes satellite imagery data from the Sentinel-2 satellite provided by the European Space Agency (ESA). It uses the visible and near-infrared bands with a **spatial resolution** of 10 meters. Sentinel-2 has a **temporal resolution** of 5 days, which means it can provide imagery of any location globally every 5 days. The combination of high resolution and high revisit frequency makes Sentinel-2 an ideal data source for analyzing changes in vegetation cover in the Gaza region.\n\n### Methodology\n\nMethod：Random Forest\n\nmath:\n$$ \\Large t = {\\frac{\\overline{x_1}-\\overline{x_2}} {\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}}} $$\n\n### Interface\n\nHow does your application's interface work to address the needs of your end user?\n\nThe following four UI designs are mainly used to meet the needs of users:\n\n1. Different colored legends were designed to represent different types of land. For example, green represents vegetation, yellow represents bare land, and gray represents urban.\n2. A dropdown menu related to time has been designed, allowing users to freely choose the year and month before and after the conflict.\n3. A line chart has been designed, allowing users to clearly see the changes in arable land area between 5 months before and after the conflict.\n4. Designed a GIF animated map, where users can see the changes in three types of land in Gaza after the conflict and download it.\n\n\n## The Application \n\nReplace the link below with the link to your application.\n\n:::{.column-page}\n\n<iframe src='https://bigdata0025.projects.earthengine.app/view/conflictupdate' width='100%' height='700px'></iframe>\n\n:::\n## How it Works \n\nUse this section to explain how your application works using code blocks and text explanations (no more than 500 words excluding code):\n\n\n### Preprocessing\n1. We've defined the meanings of the data stored in the object in the code: year, month, and pathSuffix are used to respectively describe the starting date, month number, and path suffix for each month.\n```js\n// 定义月份的开始和结束日期\nvar dates = [\n  {year: 2022, month: '11', pathSuffix: '2022_11'},\n  //{year: 2022, month: '12', pathSuffix: '2022_12'},\n  //{year: 2023, month: '01', pathSuffix: '2023_01'},\n  //{year: 2023, month: '02', pathSuffix: '2023_02'},\n  //{year: 2023, month: '03', pathSuffix: '2023_03'},\n  //{year: 2023, month: '11', pathSuffix: '2023_11'},\n // {year: 2023, month: '12', pathSuffix: '2023_12'},\n  //{year: 2024, month: '01', pathSuffix: '2024_01'},\n  //{year: 2024, month: '02', pathSuffix: '2024_02'},\n  //{year: 2024, month: '03', pathSuffix: '2024_03'}\n];\n```\n2. We've defined visualization parameters. min and max represent the minimum and maximum values of the data, while bands specify the bands to be displayed in the image. \nHere, three bands are used: 'B4', 'B3', and 'B2', corresponding to the red, green, and blue bands, typically employed for creating color images.\n```js\n// 定义可视化参数\nvar s_rgb = {\n  min: 0.0,\n  max: 6000,\n  bands:['B4', 'B3', 'B2'],\n // bands:['B8', 'B4', 'B3'], // 使用近红外、红、绿波段的假彩色合成 \n  opacity:1\n};\n```\n3. This code segment filters, processes, and visualizes the acquired Sentinel image collection. We've selected all images within the time range where cloud cover is less than 15%. \nThen, we calculated the median of these images based on the specified bands to generate a composite image.\n```js\ndates.forEach(function(dateRange) {\n  var start = dateRange.year + '-' + dateRange.month + '-01';\n  var end = new Date(dateRange.year, dateRange.month, 0).toISOString().split('T')[0]; // Auto-adjust month length\n  var sentinel = ee.ImageCollection('COPERNICUS/S2_SR')\n                    .filter(ee.Filter.date(start, end))\n                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 15))\n                    .select(bands) // 确保在过滤之前选择一致的波段集合\n                    .median();\n```\n4. Additionally, the code calculates the Normalized Difference Water Index (NDWI) and removes pixels from the composite image where the NDWI value is less than 0.3.\n```js\n  var ndwi = sentinel.normalizedDifference(['B3','B8']).rename('ndwi');\n  var image = sentinel.updateMask(ndwi.lt(0.3)).select(bands);\n  \n\n  Map.addLayer(image.clip(aoi), s_rgb, 'Sentinel ' + dateRange.year + '-' + dateRange.month);\n```\n5. This portion of the code loads a FeatureCollection of land types for a specific month. \nIt specifies the dataset path for the specific month and stores it in the variable landTypes.\n```js\n  // 加载特定月份的FeatureCollection\n  var basePath = 'projects/ucfnqma/assets/Gaza/land_types_' + dateRange.pathSuffix;\n  var landTypes = ee.FeatureCollection(basePath);\n```\n6. The next segment of code is used to generate sample point collections for vegetation, bare soil, and urban classes respectively in Google Earth Engine.\n It adds a class label to each sample point to facilitate tasks such as land cover classification or supervised learning.\n```js\n  // 为每种landType生成样本点\n  var vegetationPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'vegetation')),\n    points: 3000 // 假设为植被类的数量\n  }).map(function(feat) { return feat.set('class', 0); });\n  \n  var barePoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'bare')),\n    points: 2000 // 假设为裸土类的数量\n  }).map(function(feat) { return feat.set('class', 1); });\n  \n  var urbanPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'urban')),\n    points: 1000 // 假设为城市类的数量\n  }).map(function(feat) { return feat.set('class', 2); });\n```\n7. This line of code merges three classes of sample point collections into one, \nand adds a random column to each sample point for subsequent operations such as image clipping.\n```js\n  // 合并所有样本点，并添加随机列以后续分割\n  var sample = vegetationPoints.merge(barePoints).merge(urbanPoints).randomColumn();\n```\n### Analysis\n8. In this section we defined the split ratio using 'var split = 0.7'.\n \n```js\n // Split sample set\n  var split = 0.7;\n  var training_sample = sample.filter(ee.Filter.lt('random', split));\n  var validation_sample = sample.filter(ee.Filter.gte('random', split));\n```\nBased on the values of the random columns, 70% of the sample points are assigned to the verification set, and the remaining 30% are kept in the training set.\n\n9.By extracting training set and validation set, the random forest model is initially fitted so that we train the model.\n```js\n  // take samples from image for training\n  var training = image.select(bands).sampleRegions({\n    collection: training_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n\n  // take samples from image for validation \n  var validation = image.select(bands).sampleRegions({\n    collection: validation_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n```\n'class' tells the model to extract class information from each sample point in the training set, \nand learn how to classify based on inputProperties during training.\n\n10.\n\n```js\n  // Trian the model\n var model = ee.Classifier.smileRandomForest(500).train({\n    features: training,\n    classProperty: 'class',\n    inputProperties: bands\n  });\n\n  // Calculate the confusion matrix for the training data\n  var trainAccuracy = training.classify(model).errorMatrix('class', 'classification');\n  print('Training error matrix: '+ dateRange.year + '-' + dateRange.month, trainAccuracy);\n  print('Training overall accuracy: '+ dateRange.year + '-' + dateRange.month, trainAccuracy.accuracy());\n\n  // Apply the RF classifier to the validation\n  var validated = validation.classify(model); // 修正使用validation而非validation_sample\n\n  // Calculate the confusion matrix for the validation data\n  var testAccuracy = validated.errorMatrix('class', 'classification');\n  print('Validation error matrix: '+ dateRange.year + '-' + dateRange.month, testAccuracy);\n  print('Validation overall accuracy: '+ dateRange.year + '-' + dateRange.month, testAccuracy.accuracy());\n```\n11.\n```js\n  var prediction = image.classify(model);\n\n  var landType_prediction = prediction.updateMask(prediction.neq(-1)); // 避免使用未分类的像素\n  Map.addLayer(landType_prediction.clip(aoi), {min: 0, max: 2, palette: ['green', 'yellow', 'grey']}, 'LandType Prediction ' + dateRange.year + '-' + dateRange.month);\n\n});\n```\n12.\n```js\nvar vegetation = ee.FeatureCollection(vegetation.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'vegetation');\n}));\n\nvar urban = ee.FeatureCollection(urban.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'urban');\n}));\n\nvar bare = ee.FeatureCollection(bare.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'bare');\n}));\n\n// 合并成一个FeatureCollection\nvar combinedFeatures = vegetation.merge(urban).merge(bare);\n```\n### Interface\n1. Create a map instance and Set the center point and zoom level of the map\n\n```js\nvar map1 = ui.Map();\nmap1.centerObject(aoi,10.5);\n```\n\n2. Add a side UI, then create a selection box to place it in the side UI. Users can select 2022-11, 2022-12, 2023-1, 2023-2, 2023-11, 2023-12, 2024-1, 2024-2, 2024-3, and call a function to update the displayed layer.\n```js\nvar imageCollection = classificationCollection.map(function(img){\n  return img.clip(aoi);\n});\n// Create a selection box \nvar select = ui.Select({\n  items: ['2022-11', '2022-12', '2023-01', '2023-02', '2023-03','2023-11', '2023-12', '2024-01', '2024-02', '2024-03'],\n  value: '2022-11',  //Default selection '2022-11'\n  placeholder: 'Choose a number',\n  onChange: function(value) {\n    // Call the function to update the map\n    updateMaps(value);\n  }\n});\n\n// Create a label\nvar label = ui.Label('Please select a time', {margin: '10px 0px 5px 0px'});\n\n// Create a panel where you can place the selection boxes and labels\nvar controlPanel = ui.Panel({\n  widgets: [label, select],\n  style: {width: '300px', padding: '10px'} , // Positioning and styling\n  layout: ui.Panel.Layout.flow('horizontal')  // Set to horizontal layout\n});\n\n// Add the map to the root panel\nui.root.widgets().reset([map1]);\n\n// Set the style of the map\nmap1.style().set('width', '65%');\n\n// Create a panel to place the control panel\nvar sidebarPanel = ui.Panel({\n  widgets: [controlPanel],\n  style: {position: 'top-right', width: '120px',height: '300px',  margin: '0px 10px 0px 0px'}\n});\n\n// Adds the sidebar panel to the root panel\nui.root.add(sidebarPanel);\n```\n\nThis is the detail of update function. In this function, we first converts a collection of images to a list, then determine the index of the image by month. \n```js\n// Converts a collection of images to a list\nvar imageList = imageCollection.toList(imageCollection.size());\n\nfunction updateMaps(month) {\n  // Determine the index of the image by month\n  var index1;\n  switch (month) {\n    case '2022-11':\n      index1 = 0;\n      break;\n    case '2022-12':\n      index1 = 1;\n      break;\n    case '2023-01':\n      index1 = 2;\n      break;\n    case '2023-02':\n      index1 = 3;\n      break;\n    case '2023-03':\n      index1 = 4;\n      break;\n    case '2023-11':\n      index1 = 5;\n      break;\n    case '2023-12':\n      index1 = 6;\n      break;\n    case '2024-01':\n      index1 = 7;\n      break;\n    case '2024-02':\n      index1 = 8;\n      break;\n    case '2024-03':\n      index1 = 9;\n      break;\n    default:\n      console.error('Invalid month selected:', month);\n      return;\n  }\n  // Get the image by index\n  var image1 = ee.Image(imageList.get(index1));\n```\n\n3. Add the legends to the map. We define the color list and description list, then create the legend style and legend panel. Add legend items in a loop. It contains description labels and color blocks, adds legend items to the inside version of the diagram, and adds legends to the lower left corner of the map.\n```js\npdateMaps('2022-11');\n\n// Define the color list and description list\nvar palette = ['green', 'yellow', 'grey']; // Suppose this is your list of colors\nvar names = ['vegetation', 'bare', 'urban']; // A description corresponding to the color\n\n// Create a style for the legend\nvar legendStyle = {\n  margin: '0px 8px 15px 0px',\n  padding: '0px 5px 5px 0px',\n  position: 'bottom-left'\n};\n\n// Create the panel of legend\nvar legendPanel = ui.Panel({\n  widgets: [], // Used to add legend entries\n  style: legendStyle\n});\n\n// Add a legend entry\nfor (var i = 0; i < palette.length; i++) {\n  var legendItem = ui.Panel({\n    layout: ui.Panel.Layout.Flow('horizontal'),\n    style: {margin: '0px 10px'}\n  });\n  \n  // create color block\n  var colorBlock = ui.Label({\n    style: {\n      backgroundColor: palette[i],\n      padding: '5px',\n      margin: '0 0 4px 0'\n    }\n  });\n  \n  // create desctription label\n  var description = ui.Label({\n    value: names[i],\n    style: {margin: '0 0 4px 8px'}\n  });\n  \n  legendItem.add(colorBlock);\n  legendItem.add(description);\n  \n  // Adds a legend item to the Legend panel\n  legendPanel.add(legendItem);\n}\n\n// Add the legend to the bottom left corner of the map\nmap1.add(legendPanel);\n```\n\n4. Before drawing a line graph of vegetation area changes before and after conflicts, we need to export the image for area calculation. (Note: Due to the high computational complexity, calling the area calculation function directly can lead to long waiting times and may cause webpage crashes. Therefore, it is necessary to export the area calculation results first.)\n\n```js\n// Batch download functions\nfunction exportImage(image, roi, fileName) {  \n  Export.image.toAsset({  \n    image: image,\n    description: 'GAZA_'+fileName,\n    region: aoi,\n    scale: 10,\n    maxPixels: 1e13, // Maximum image element\n  });  \n}\n\n// Generate the list and download iteratively\nvar indexList = classificationCollection.reduceColumns(ee.Reducer.toList(), [\"system:index\"]).get(\"list\"); \nprint(\"indexList\", indexList);\nindexList.evaluate(function(indexs) { \n  for (var i=0; i<indexs.length; i++) {  \n    var image = classificationCollection.filter(ee.Filter.eq(\"system:index\", indexs[i]))\n      .first()\n    var name=parseInt(indexs[i])\n        \n    exportImage(image, aoi, name);  //Save the image to Asset\n  }\n}); \n\nvar aoi = ee.FeatureCollection('users/liujingyue01/Gaza');\nvar imageCollection=ee.ImageCollection('projects/hongkairen81/assets/GAZA');\nprint(imageCollection)\n\n// Calculating the vegetation area as a function\nfunction calculateVegetationArea(image) {\n  var vegetationArea = image.select('classification').eq(0).multiply(ee.Image.pixelArea()).reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 30\n  }).get('classification');\n  return ee.Feature(null, {'date': image.get('date'), 'vegetationArea': vegetationArea});\n}\n\n// Apply a function to each Image in the imageCollection\nvar vegetationAreas = imageCollection.map(calculateVegetationArea).sort('date');\n\n// Convert the result to a list\nvar vegetationAreaList = vegetationAreas.toList(vegetationAreas.size());\nprint(vegetationAreaList)\nvar firstFive = ee.List.sequence(0, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n// var lastFive = ee.List.sequence(5, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n\n// Convert the area to a numerical value\nvar firstFiveNumbers = firstFive.map(function(area) { return ee.Number(area); });\nprint(firstFiveNumbers)\n```\n5. Draw the area calculation results onto a line graph. Set two y values before and after the conflict, which are two lines.\n\n```js\nvar firstFiveNumbers = ee.List([ 108.981451,\n  124.064503,\n  156.647346,\n  160.888861,\n  191.688693]);\nvar lastFiveNumbers = ee.List([145.504210,\n  160.795185,\n  125.786433,\n  105.063353, \n  107.703722]);\n\n// Abscissa data\nvar xAxis = ['11', '12', '1', '2', '3'];\n\n// Create a data source in the DataTable format that conforms to the Google Visualization API\nvar chartData = ee.FeatureCollection(xAxis.map(function(x, index) {\n  return ee.Feature(null, {\n    'x': x,\n    'y1': firstFiveNumbers.get(index),\n    'y2': lastFiveNumbers.get(index)\n  });\n}));\n\n// Create a line chart using ui.Chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2'] // Add two sets of y values\n}).setSeriesNames(['Before the conflict', 'After the conflict']) // Set series name\n  .setOptions({\n    title: 'Comparison of areas before and after the conflict',\n    hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n    vAxis: {title: 'vegetation Area', titleTextStyle: {color: 'blue'}},\n    legend: 'right' // Display legend\n  });\n\n// Set the size of the chart\nvar options = {\n  title: 'Comparison of areas before and after the conflict',\n  hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n  vAxis: {title: 'vegetation Area (km^2)', titleTextStyle: {color: 'blue'}},\n  legend: 'right',\n  width: 400, // Set chart width\n  height: 300 // Set chart height\n};\n\n// Create a line chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2']\n}).setSeriesNames(['Before the cnflict', 'After the conflict']).setOptions(options);\n\n// Adjust the style of the sidebar panel to ensure that there is enough space to display the chart\nsidebarPanel.style().set({\n  width: '400px', // Sets the minimum width of the panel\n  height: 'auto' // Automatically adjust the height according to the content\n});\n\n// Adds a line chart to the sidebar panel\nsidebarPanel.add(lineChart);\n```\n\n6. Draw a GIF image of post conflict land changes (November 2023.11-204.3) and place it in the side UI.\n\n```js\n//show gif\nfunction main() {\n  //Assume that the roi is defined and is a Feature or FeatureCollection\n  var roi = aoi;\n\n  // Let's say imgCol is defined and it contains 10 single-band images\n  var imgCol = classificationCollection.map(function(image){\n    return image.clip(roi);\n  });\n  \n  // Gets the number of images in the collection\n  var count =imgCol.toList(imgCol.size()).length();\n\n  // Calculate the number of images to skip\n  var skipCount = 5;\n\n  // Skip the previous images to get the last five images\n  var lastFiveImages = classificationCollection.toList(classificationCollection.size())\n  .slice(skipCount, count);\n\n  // Converts a list back to a collection of images\n  imgCol = ee.ImageCollection.fromImages(lastFiveImages).map(function(img){\n    return img.clip(aoi)\n  });\n\n  // Defines a function to map a single-band image to an RGB color\n  function mapToRgb(image) {\n    // Get a single band image\n    var band = image.select([0]);\n\n    // Creates a new image with the same R, G, and B values for each pixel\n    var r = band.where(band.eq(0), 0).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var g = band.where(band.eq(0), 128).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var b = band.where(band.eq(0), 0).where(band.eq(1), 0).where(band.eq(2), 200).toInt();\n\n    // Returns a new image containing the RGB band\n    return ee.Image.cat(r, g, b).rename(['red', 'green', 'blue']).toFloat();\n  }\n\n  // Map each image to an RGB color\n  var rgbImgCol = imgCol.map(mapToRgb);\n\n  // GIF parameters\n  var params = {\n    crs: 'EPSG:3857',\n    framesPerSecond: 2,\n    region: roi.geometry().transform('EPSG:3857', 1), // Use the converted region\n    min: 0,\n    max: 255,\n    bands: ['red', 'green', 'blue'],\n    dimensions: 512,\n  };\n\n  // Add the GIF to the panel\n  sidebarPanel.add(ui.Thumbnail(rgbImgCol, params));\n  \n}\n\nmain();\n```\n\n7. Create a tag and set the tag's hyperlink to download the GIF.\n\n```js\n// Create a label\nvar label = ui.Label('Download the GIF of \"Changing Land Conditions in Conflict\".');\n\n// Set the URL of the tag to make it a hyperlink\nlabel.setUrl(rgbImgCol.getVideoThumbURL(params));\n\nsidebarPanel.add(label);\n```\n\n\nThe image output should look like this:\n\n![Changing Land conditions in Conflict, 2023.11-2024.3](images/conflict.gif)\n\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"monokai.theme","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","book":{"title":"CASA0025 Final Assessment","author":"Group Name","date":"01/01/2024","chapters":["index.qmd"],"repo-actions":["edit"],"downloads":["pdf","epub"],"sharing":["twitter","facebook"],"favicon":"favicon.ico","sidebar":{"logo":"casa_logo.png"}},"theme":{"dark":"darkly","light":"cosmo"},"code-copy":true,"linkcolor":"#34a832"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}