[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "",
    "section": "",
    "text": "Use this repository to host a website for your CASA0025 final project by following these stpes:\n\nclone this repository\ninstall quarto\nedit the ‘index.qmd’ file with the contents of your project\nusing terminal, navigate to the project directory and run “quarto render”\npush the changes to your github repository\non github, navigate to Settings&gt;Pages&gt;Build and Deployment. Make sure that under “Source” it says “deploy from branch”. Under “Branch”, select “Main” in the first dropdown and “Docs” under the second drop down. Then press “Save”\n\nYour website should now be available under https://imhonggae.github.io/CASA0025"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA00025 Gaza",
    "section": "",
    "text": "This application is based on remote sensing technology and machine learning algorithms to assess vegetation cover changes in Gaza during the Palestinian-Israeli conflict. Based on Sentinel-2 satellite data and the Google Earth Engine platform, the application adopts an automated image preprocessing process (including image extraction, image synthesis, and masking) and utilizes the Random Forest algorithm to develop a classifier to distinguish between three different types of land cover: vegetation, bare land, and urban areas. The project aims to reveal changes in vegetation cover in the Gaza by generating and comparing land cover classification maps before and after the conflict, thereby providing clear evidence to assess the ongoing humanitarian crisis and urban destruction in the Gaza area.\n\n\nChallenges in Monitoring Vegetation Cover:\nDue to the ongoing conflict in the Gaza area, ground access is extremely limited, making traditional surveying methods unfeasible and accurate information on vegetation status and changes unattainable. This project utilize remote sensing technology and machine learning methods to provide a safe and effective way to monitor vegetation cover changes from a distance, thus solving the challenges of on-site measurement.\nHumanitarian Crisis and Food Dependency in Gaza:\nGaza is one of the most densely populated areas in the world and faces chronic food shortages, heavily relying on international aid. The escalation of the Israel-Palestine conflict has led to the severance of aid supply channels, further increasing the local population’s dependency on limited arable land resources. In this context, remote sensing data analysis can effectively assess the impact of the conflict on agricultural land, thereby quantifying the severity of the humanitarian crisis.\n\n\n\nInternational Aid and Humanitarian Organizations:\nHumanitarian organizations require accurate data to assess the impact of conflicts on local ecology and agricultural productivity, to optimize their aid plans and resource allocation. The remote sensing analysis provided by this project can guide them in formulating more effective rescue and assistance strategies during emergencies.\nRegional Research Scholars:\nFor the Gaza region, which relies heavily on agricultural production, understanding changes in vegetation cover is crucial for adjusting agricultural production plans and farming methods. The results of this project can aid researchers studying the food structure of this region in predicting yield changes and providing sound advice to address Gaza’s food shortage issues.\nPublic and Media:\nThe results processed through professional technical methods can be visually presented to the public and media, thereby drawing broader attention to the ongoing humanitarian crisis in the Gaza area through more extensive channels.\n\n\n\nThis software utilizes satellite imagery data from the Sentinel-2 satellite provided by the European Space Agency (ESA). It uses the visible and near-infrared bands with a spatial resolution of 10 meters. Sentinel-2 has a temporal resolution of 5 days, which means it can provide imagery of any location globally every 5 days. The combination of high resolution and high revisit frequency makes Sentinel-2 an ideal data source for analyzing changes in vegetation cover in the Gaza region.\n\n\n\n1.Random Forest- for classification\n\n2.Confusion Matrix - for validation\nConfusion Matrix Accuracy Formula:\n\\[\\begin{equation} Accuracy = \\frac{TP + TN}{TP + FP + FN + TN}\\end{equation}\\]\nTP: the number of cases that the model correctly predicted as positive. (True Positive)\nFP: the number of negative cases that the model incorrectly predicted as positive (False Positive)\nFN: the number of positive cases that the model incorrectly predicted as negative (False Negative)\nTN: the number of negative cases that the model correctly predicted as negative (True Negative)\n3.Comparison Validation:\nThe land use type predicted by the model is compared with the actual picture to judge whether the model result is correct.\n\n\n\nThe following four UI designs are mainly used to meet the needs of users:\n\nDifferent colored legends were designed to represent different types of land. For example, green represents vegetation, yellow represents bare land, and gray represents urban.\nA dropdown menu related to time has been designed, allowing users to freely choose the year and month before and after the conflict.\nA line chart has been designed, allowing users to clearly see the changes in arable land area between 5 months before and after the conflict.\nDesigned a GIF animated map, where users can see the changes in three types of land in Gaza after the conflict and download it.\n\n\n\n\n\nReplace the link below with the link to your application.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ve defined the meanings of the data stored in the object in the code: year, month, and pathSuffix are used to respectively describe the starting date, month number, and path suffix for each month.\n\n// 定义月份的开始和结束日期\nvar dates = [\n  {year: 2022, month: '11', pathSuffix: '2022_11'},\n  //{year: 2022, month: '12', pathSuffix: '2022_12'},\n  //{year: 2023, month: '01', pathSuffix: '2023_01'},\n  //{year: 2023, month: '02', pathSuffix: '2023_02'},\n  //{year: 2023, month: '03', pathSuffix: '2023_03'},\n  //{year: 2023, month: '11', pathSuffix: '2023_11'},\n // {year: 2023, month: '12', pathSuffix: '2023_12'},\n  //{year: 2024, month: '01', pathSuffix: '2024_01'},\n  //{year: 2024, month: '02', pathSuffix: '2024_02'},\n  //{year: 2024, month: '03', pathSuffix: '2024_03'}\n];\n\nWe’ve defined visualization parameters. min and max represent the minimum and maximum values of the data, while bands specify the bands to be displayed in the image. Here, three bands are used: ‘B4’, ‘B3’, and ‘B2’, corresponding to the red, green, and blue bands, typically employed for creating color images.\n\n// 定义可视化参数\nvar s_rgb = {\n  min: 0.0,\n  max: 6000,\n  bands:['B4', 'B3', 'B2'],\n // bands:['B8', 'B4', 'B3'], // 使用近红外、红、绿波段的假彩色合成 \n  opacity:1\n};\n\nThis code segment filters, processes, and visualizes the acquired Sentinel image collection. We’ve selected all images within the time range where cloud cover is less than 15%. Then, we calculated the median of these images based on the specified bands to generate a composite image.\n\ndates.forEach(function(dateRange) {\n  var start = dateRange.year + '-' + dateRange.month + '-01';\n  var end = new Date(dateRange.year, dateRange.month, 0).toISOString().split('T')[0]; // Auto-adjust month length\n  var sentinel = ee.ImageCollection('COPERNICUS/S2_SR')\n                    .filter(ee.Filter.date(start, end))\n                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 15))\n                    .select(bands) // 确保在过滤之前选择一致的波段集合\n                    .median();\n\nAdditionally, the code calculates the Normalized Difference Water Index (NDWI) and removes pixels from the composite image where the NDWI value is less than 0.3.\n\n  var ndwi = sentinel.normalizedDifference(['B3','B8']).rename('ndwi');\n  var image = sentinel.updateMask(ndwi.lt(0.3)).select(bands);\n  \n\n  Map.addLayer(image.clip(aoi), s_rgb, 'Sentinel ' + dateRange.year + '-' + dateRange.month);\n\nThis portion of the code loads a FeatureCollection of land types for a specific month. It specifies the dataset path for the specific month and stores it in the variable landTypes.\n\n  // 加载特定月份的FeatureCollection\n  var basePath = 'projects/ucfnqma/assets/Gaza/land_types_' + dateRange.pathSuffix;\n  var landTypes = ee.FeatureCollection(basePath);\n\nThe next segment of code is used to generate sample point collections for vegetation, bare soil, and urban classes respectively in Google Earth Engine. It adds a class label to each sample point to facilitate tasks such as land cover classification or supervised learning.\n\n  // 为每种landType生成样本点\n  var vegetationPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'vegetation')),\n    points: 3000 // 假设为植被类的数量\n  }).map(function(feat) { return feat.set('class', 0); });\n  \n  var barePoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'bare')),\n    points: 2000 // 假设为裸土类的数量\n  }).map(function(feat) { return feat.set('class', 1); });\n  \n  var urbanPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'urban')),\n    points: 1000 // 假设为城市类的数量\n  }).map(function(feat) { return feat.set('class', 2); });\n\nThis line of code merges three classes of sample point collections into one, and adds a random column to each sample point for subsequent operations such as image clipping.\n\n  // 合并所有样本点，并添加随机列以后续分割\n  var sample = vegetationPoints.merge(barePoints).merge(urbanPoints).randomColumn();\n\n\n\n\nIn this section we defined the split ratio using ‘var split = 0.7’.\n\n // Split sample set\n  var split = 0.7;\n  var training_sample = sample.filter(ee.Filter.lt('random', split));\n  var validation_sample = sample.filter(ee.Filter.gte('random', split));\nBased on the values of the random columns, 70% of the sample points are assigned to the verification set, and the remaining 30% are kept in the training set.\n\nBy extracting training set and validation set, the random forest model is initially fitted so that we train the model.\n\n  // take samples from image for training\n  var training = image.select(bands).sampleRegions({\n    collection: training_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n\n  // take samples from image for validation \n  var validation = image.select(bands).sampleRegions({\n    collection: validation_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n10.This section trains the model by fitting it with a training set and a validation set\n  // Trian the model\n var model = ee.Classifier.smileRandomForest(500).train({\n    features: training,\n    classProperty: 'class',\n    inputProperties: bands\n  });\n\n  // Calculate the confusion matrix for the training data\n  var trainAccuracy = training.classify(model).errorMatrix('class', 'classification');\n  print('Training error matrix: '+ dateRange.year + '-' + dateRange.month, trainAccuracy);\n  print('Training overall accuracy: '+ dateRange.year + '-' + dateRange.month, trainAccuracy.accuracy());\n\n  // Apply the RF classifier to the validation\n  var validated = validation.classify(model); // Fix using validation instead of validation_sample\n\n  // Calculate the confusion matrix for the validation data\n  var testAccuracy = validated.errorMatrix('class', 'classification');\n  print('Validation error matrix: '+ dateRange.year + '-' + dateRange.month, testAccuracy);\n  print('Validation overall accuracy: '+ dateRange.year + '-' + dateRange.month, testAccuracy.accuracy());\nThe function of the model is chosen such that we use ‘class’ read data for categorical prediction.\n11.After fitting the model, we use the overall image to classify the prediction using the dataset\n  var prediction = image.classify(model);\n\n  var landType_prediction = prediction.updateMask(prediction.neq(-1)); // Avoid using unclassified pixels\n  Map.addLayer(landType_prediction.clip(aoi), {min: 0, max: 2, palette: ['green', 'yellow', 'grey']}, 'LandType Prediction ' + dateRange.year + '-' + dateRange.month);\n\n});\n12.For a better view of the results, combine all results into one layer feature.\nvar vegetation = ee.FeatureCollection(vegetation.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'vegetation');\n}));\n\nvar urban = ee.FeatureCollection(urban.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'urban');\n}));\n\nvar bare = ee.FeatureCollection(bare.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'bare');\n}));\n\n// 合并成一个FeatureCollection\nvar combinedFeatures = vegetation.merge(urban).merge(bare);\n\n\n\nExport.table.toAsset({\n  collection: combinedFeatures,\n  description: 'land_types_2022_11',\n  assetId: 'projects/ucfnqma/assets/Gaza/land_types_2022_11'});\n\n\n\n\n\nCreate a map instance and Set the center point and zoom level of the map\n\nvar map1 = ui.Map();\nmap1.centerObject(aoi,10.5);\n\nAdd a side UI, then create a selection box to place it in the side UI. Users can select 2022-11, 2022-12, 2023-1, 2023-2, 2023-11, 2023-12, 2024-1, 2024-2, 2024-3, and call a function to update the displayed layer.\n\nvar imageCollection = classificationCollection.map(function(img){\n  return img.clip(aoi);\n});\n// Create a selection box \nvar select = ui.Select({\n  items: ['2022-11', '2022-12', '2023-01', '2023-02', '2023-03','2023-11', '2023-12', '2024-01', '2024-02', '2024-03'],\n  value: '2022-11',  //Default selection '2022-11'\n  placeholder: 'Choose a number',\n  onChange: function(value) {\n    // Call the function to update the map\n    updateMaps(value);\n  }\n});\n\n// Create a label\nvar label = ui.Label('Please select a time', {margin: '10px 0px 5px 0px'});\n\n// Create a panel where you can place the selection boxes and labels\nvar controlPanel = ui.Panel({\n  widgets: [label, select],\n  style: {width: '300px', padding: '10px'} , // Positioning and styling\n  layout: ui.Panel.Layout.flow('horizontal')  // Set to horizontal layout\n});\n\n// Add the map to the root panel\nui.root.widgets().reset([map1]);\n\n// Set the style of the map\nmap1.style().set('width', '65%');\n\n// Create a panel to place the control panel\nvar sidebarPanel = ui.Panel({\n  widgets: [controlPanel],\n  style: {position: 'top-right', width: '120px',height: '300px',  margin: '0px 10px 0px 0px'}\n});\n\n// Adds the sidebar panel to the root panel\nui.root.add(sidebarPanel);\nThis is the detail of update function. In this function, we first converts a collection of images to a list, then determine the index of the image by month.\n// Converts a collection of images to a list\nvar imageList = imageCollection.toList(imageCollection.size());\n\nfunction updateMaps(month) {\n  // Determine the index of the image by month\n  var index1;\n  switch (month) {\n    case '2022-11':\n      index1 = 0;\n      break;\n    case '2022-12':\n      index1 = 1;\n      break;\n    case '2023-01':\n      index1 = 2;\n      break;\n    case '2023-02':\n      index1 = 3;\n      break;\n    case '2023-03':\n      index1 = 4;\n      break;\n    case '2023-11':\n      index1 = 5;\n      break;\n    case '2023-12':\n      index1 = 6;\n      break;\n    case '2024-01':\n      index1 = 7;\n      break;\n    case '2024-02':\n      index1 = 8;\n      break;\n    case '2024-03':\n      index1 = 9;\n      break;\n    default:\n      console.error('Invalid month selected:', month);\n      return;\n  }\n  // Get the image by index\n  var image1 = ee.Image(imageList.get(index1));\n\nAdd the legends to the map. We define the color list and description list, then create the legend style and legend panel. Add legend items in a loop. It contains description labels and color blocks, adds legend items to the inside version of the diagram, and adds legends to the lower left corner of the map.\n\npdateMaps('2022-11');\n\n// Define the color list and description list\nvar palette = ['green', 'yellow', 'grey']; // Suppose this is your list of colors\nvar names = ['vegetation', 'bare', 'urban']; // A description corresponding to the color\n\n// Create a style for the legend\nvar legendStyle = {\n  margin: '0px 8px 15px 0px',\n  padding: '0px 5px 5px 0px',\n  position: 'bottom-left'\n};\n\n// Create the panel of legend\nvar legendPanel = ui.Panel({\n  widgets: [], // Used to add legend entries\n  style: legendStyle\n});\n\n// Add a legend entry\nfor (var i = 0; i &lt; palette.length; i++) {\n  var legendItem = ui.Panel({\n    layout: ui.Panel.Layout.Flow('horizontal'),\n    style: {margin: '0px 10px'}\n  });\n  \n  // create color block\n  var colorBlock = ui.Label({\n    style: {\n      backgroundColor: palette[i],\n      padding: '5px',\n      margin: '0 0 4px 0'\n    }\n  });\n  \n  // create desctription label\n  var description = ui.Label({\n    value: names[i],\n    style: {margin: '0 0 4px 8px'}\n  });\n  \n  legendItem.add(colorBlock);\n  legendItem.add(description);\n  \n  // Adds a legend item to the Legend panel\n  legendPanel.add(legendItem);\n}\n\n// Add the legend to the bottom left corner of the map\nmap1.add(legendPanel);\n\nBefore drawing a line graph of vegetation area changes before and after conflicts, we need to export the image for area calculation. (Note: Due to the high computational complexity, calling the area calculation function directly can lead to long waiting times and may cause webpage crashes. Therefore, it is necessary to export the area calculation results first.)\n\n// Batch download functions\nfunction exportImage(image, roi, fileName) {  \n  Export.image.toAsset({  \n    image: image,\n    description: 'GAZA_'+fileName,\n    region: aoi,\n    scale: 10,\n    maxPixels: 1e13, // Maximum image element\n  });  \n}\n\n// Generate the list and download iteratively\nvar indexList = classificationCollection.reduceColumns(ee.Reducer.toList(), [\"system:index\"]).get(\"list\"); \nprint(\"indexList\", indexList);\nindexList.evaluate(function(indexs) { \n  for (var i=0; i&lt;indexs.length; i++) {  \n    var image = classificationCollection.filter(ee.Filter.eq(\"system:index\", indexs[i]))\n      .first()\n    var name=parseInt(indexs[i])\n        \n    exportImage(image, aoi, name);  //Save the image to Asset\n  }\n}); \n\nvar aoi = ee.FeatureCollection('users/liujingyue01/Gaza');\nvar imageCollection=ee.ImageCollection('projects/ee-guo112591/assets/GAZA');\n\n// Calculating the vegetation area as a function\nfunction calculateVegetationArea(image) {\n  var vegetationArea = image.select('classification').eq(0).multiply(ee.Image.pixelArea()).reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 30\n  }).get('classification');\n  return ee.Feature(null, {'date': image.get('date'), 'vegetationArea': vegetationArea});\n}\n\n// Apply a function to each Image in the imageCollection\nvar vegetationAreas = imageCollection.map(calculateVegetationArea).sort('date');\n\n// Convert the result to a list\nvar vegetationAreaList = vegetationAreas.toList(vegetationAreas.size());\nprint(vegetationAreaList)\nvar firstFive = ee.List.sequence(0, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n// var lastFive = ee.List.sequence(5, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n\n// Convert the area to a numerical value\nvar firstFiveNumbers = firstFive.map(function(area) { return ee.Number(area); });\nprint(firstFiveNumbers)\n\nDraw the area calculation results onto a line graph. Set two y values before and after the conflict, which are two lines.\n\nvar firstFiveNumbers = ee.List([ 108.981451,\n  124.064503,\n  156.647346,\n  160.888861,\n  191.688693]);\nvar lastFiveNumbers = ee.List([145.504210,\n  160.795185,\n  125.786433,\n  105.063353, \n  107.703722]);\n\n// Abscissa data\nvar xAxis = ['11', '12', '1', '2', '3'];\n\n// Create a data source in the DataTable format that conforms to the Google Visualization API\nvar chartData = ee.FeatureCollection(xAxis.map(function(x, index) {\n  return ee.Feature(null, {\n    'x': x,\n    'y1': firstFiveNumbers.get(index),\n    'y2': lastFiveNumbers.get(index)\n  });\n}));\n\n// Create a line chart using ui.Chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2'] // Add two sets of y values\n}).setSeriesNames(['Before the conflict', 'After the conflict']) // Set series name\n  .setOptions({\n    title: 'Comparison of areas before and after the conflict',\n    hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n    vAxis: {title: 'vegetation Area', titleTextStyle: {color: 'blue'}},\n    legend: 'right' // Display legend\n  });\n\n// Set the size of the chart\nvar options = {\n  title: 'Comparison of areas before and after the conflict',\n  hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n  vAxis: {title: 'vegetation Area (km^2)', titleTextStyle: {color: 'blue'}},\n  legend: 'right',\n  width: 400, // Set chart width\n  height: 300 // Set chart height\n};\n\n// Create a line chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2']\n}).setSeriesNames(['Before the cnflict', 'After the conflict']).setOptions(options);\n\n// Adjust the style of the sidebar panel to ensure that there is enough space to display the chart\nsidebarPanel.style().set({\n  width: '400px', // Sets the minimum width of the panel\n  height: 'auto' // Automatically adjust the height according to the content\n});\n\n// Adds a line chart to the sidebar panel\nsidebarPanel.add(lineChart);\n\nDraw a GIF image of post conflict land changes (November 2023.11-204.3) and place it in the side UI.\n\n//show gif\nfunction main() {\n  //Assume that the roi is defined and is a Feature or FeatureCollection\n  var roi = aoi;\n\n  // Let's say imgCol is defined and it contains 10 single-band images\n  var imgCol = classificationCollection.map(function(image){\n    return image.clip(roi);\n  });\n  \n  // Gets the number of images in the collection\n  var count =imgCol.toList(imgCol.size()).length();\n\n  // Calculate the number of images to skip\n  var skipCount = 5;\n\n  // Skip the previous images to get the last five images\n  var lastFiveImages = classificationCollection.toList(classificationCollection.size())\n  .slice(skipCount, count);\n\n  // Converts a list back to a collection of images\n  imgCol = ee.ImageCollection.fromImages(lastFiveImages).map(function(img){\n    return img.clip(aoi)\n  });\n\n  // Defines a function to map a single-band image to an RGB color\n  function mapToRgb(image) {\n    // Get a single band image\n    var band = image.select([0]);\n\n    // Creates a new image with the same R, G, and B values for each pixel\n    var r = band.where(band.eq(0), 0).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var g = band.where(band.eq(0), 128).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var b = band.where(band.eq(0), 0).where(band.eq(1), 0).where(band.eq(2), 200).toInt();\n\n    // Returns a new image containing the RGB band\n    return ee.Image.cat(r, g, b).rename(['red', 'green', 'blue']).toFloat();\n  }\n\n  // Map each image to an RGB color\n  var rgbImgCol = imgCol.map(mapToRgb);\n\n  // GIF parameters\n  var params = {\n    crs: 'EPSG:3857',\n    framesPerSecond: 2,\n    region: roi.geometry().transform('EPSG:3857', 1), // Use the converted region\n    min: 0,\n    max: 255,\n    bands: ['red', 'green', 'blue'],\n    dimensions: 512,\n  };\n\n  // Add the GIF to the panel\n  sidebarPanel.add(ui.Thumbnail(rgbImgCol, params));\n  \n}\n\nmain();\n\nCreate a tag and set the tag’s hyperlink to download the GIF.\n\n// Create a label\nvar label = ui.Label('Download the GIF of \"Changing Land Conditions in Conflict\".');\n\n// Set the URL of the tag to make it a hyperlink\nlabel.setUrl(rgbImgCol.getVideoThumbURL(params));\n\nsidebarPanel.add(label);\nThe image output should look like this:\n\n\n\nChanging Land conditions in Conflict, 2023.11-2024.3"
  },
  {
    "objectID": "index.html#project-summary",
    "href": "index.html#project-summary",
    "title": "CASA00025 Gaza",
    "section": "",
    "text": "This application is based on remote sensing technology and machine learning algorithms to assess vegetation cover changes in Gaza during the Palestinian-Israeli conflict. Based on Sentinel-2 satellite data and the Google Earth Engine platform, the application adopts an automated image preprocessing process (including image extraction, image synthesis, and masking) and utilizes the Random Forest algorithm to develop a classifier to distinguish between three different types of land cover: vegetation, bare land, and urban areas. The project aims to reveal changes in vegetation cover in the Gaza by generating and comparing land cover classification maps before and after the conflict, thereby providing clear evidence to assess the ongoing humanitarian crisis and urban destruction in the Gaza area.\n\n\nChallenges in Monitoring Vegetation Cover:\nDue to the ongoing conflict in the Gaza area, ground access is extremely limited, making traditional surveying methods unfeasible and accurate information on vegetation status and changes unattainable. This project utilize remote sensing technology and machine learning methods to provide a safe and effective way to monitor vegetation cover changes from a distance, thus solving the challenges of on-site measurement.\nHumanitarian Crisis and Food Dependency in Gaza:\nGaza is one of the most densely populated areas in the world and faces chronic food shortages, heavily relying on international aid. The escalation of the Israel-Palestine conflict has led to the severance of aid supply channels, further increasing the local population’s dependency on limited arable land resources. In this context, remote sensing data analysis can effectively assess the impact of the conflict on agricultural land, thereby quantifying the severity of the humanitarian crisis.\n\n\n\nInternational Aid and Humanitarian Organizations:\nHumanitarian organizations require accurate data to assess the impact of conflicts on local ecology and agricultural productivity, to optimize their aid plans and resource allocation. The remote sensing analysis provided by this project can guide them in formulating more effective rescue and assistance strategies during emergencies.\nRegional Research Scholars:\nFor the Gaza region, which relies heavily on agricultural production, understanding changes in vegetation cover is crucial for adjusting agricultural production plans and farming methods. The results of this project can aid researchers studying the food structure of this region in predicting yield changes and providing sound advice to address Gaza’s food shortage issues.\nPublic and Media:\nThe results processed through professional technical methods can be visually presented to the public and media, thereby drawing broader attention to the ongoing humanitarian crisis in the Gaza area through more extensive channels.\n\n\n\nThis software utilizes satellite imagery data from the Sentinel-2 satellite provided by the European Space Agency (ESA). It uses the visible and near-infrared bands with a spatial resolution of 10 meters. Sentinel-2 has a temporal resolution of 5 days, which means it can provide imagery of any location globally every 5 days. The combination of high resolution and high revisit frequency makes Sentinel-2 an ideal data source for analyzing changes in vegetation cover in the Gaza region.\n\n\n\n1.Random Forest- for classification\n\n2.Confusion Matrix - for validation\nConfusion Matrix Accuracy Formula:\n\\[\\begin{equation} Accuracy = \\frac{TP + TN}{TP + FP + FN + TN}\\end{equation}\\]\nTP: the number of cases that the model correctly predicted as positive. (True Positive)\nFP: the number of negative cases that the model incorrectly predicted as positive (False Positive)\nFN: the number of positive cases that the model incorrectly predicted as negative (False Negative)\nTN: the number of negative cases that the model correctly predicted as negative (True Negative)\n3.Comparison Validation:\nThe land use type predicted by the model is compared with the actual picture to judge whether the model result is correct.\n\n\n\nThe following four UI designs are mainly used to meet the needs of users:\n\nDifferent colored legends were designed to represent different types of land. For example, green represents vegetation, yellow represents bare land, and gray represents urban.\nA dropdown menu related to time has been designed, allowing users to freely choose the year and month before and after the conflict.\nA line chart has been designed, allowing users to clearly see the changes in arable land area between 5 months before and after the conflict.\nDesigned a GIF animated map, where users can see the changes in three types of land in Gaza after the conflict and download it."
  },
  {
    "objectID": "index.html#the-application",
    "href": "index.html#the-application",
    "title": "CASA00025 Gaza",
    "section": "",
    "text": "Replace the link below with the link to your application."
  },
  {
    "objectID": "index.html#classification-and-projection-of-land-use-types-in-gaza",
    "href": "index.html#classification-and-projection-of-land-use-types-in-gaza",
    "title": "CASA00025 Gaza",
    "section": "",
    "text": "We’ve defined the meanings of the data stored in the object in the code: year, month, and pathSuffix are used to respectively describe the starting date, month number, and path suffix for each month.\n\n// 定义月份的开始和结束日期\nvar dates = [\n  {year: 2022, month: '11', pathSuffix: '2022_11'},\n  //{year: 2022, month: '12', pathSuffix: '2022_12'},\n  //{year: 2023, month: '01', pathSuffix: '2023_01'},\n  //{year: 2023, month: '02', pathSuffix: '2023_02'},\n  //{year: 2023, month: '03', pathSuffix: '2023_03'},\n  //{year: 2023, month: '11', pathSuffix: '2023_11'},\n // {year: 2023, month: '12', pathSuffix: '2023_12'},\n  //{year: 2024, month: '01', pathSuffix: '2024_01'},\n  //{year: 2024, month: '02', pathSuffix: '2024_02'},\n  //{year: 2024, month: '03', pathSuffix: '2024_03'}\n];\n\nWe’ve defined visualization parameters. min and max represent the minimum and maximum values of the data, while bands specify the bands to be displayed in the image. Here, three bands are used: ‘B4’, ‘B3’, and ‘B2’, corresponding to the red, green, and blue bands, typically employed for creating color images.\n\n// 定义可视化参数\nvar s_rgb = {\n  min: 0.0,\n  max: 6000,\n  bands:['B4', 'B3', 'B2'],\n // bands:['B8', 'B4', 'B3'], // 使用近红外、红、绿波段的假彩色合成 \n  opacity:1\n};\n\nThis code segment filters, processes, and visualizes the acquired Sentinel image collection. We’ve selected all images within the time range where cloud cover is less than 15%. Then, we calculated the median of these images based on the specified bands to generate a composite image.\n\ndates.forEach(function(dateRange) {\n  var start = dateRange.year + '-' + dateRange.month + '-01';\n  var end = new Date(dateRange.year, dateRange.month, 0).toISOString().split('T')[0]; // Auto-adjust month length\n  var sentinel = ee.ImageCollection('COPERNICUS/S2_SR')\n                    .filter(ee.Filter.date(start, end))\n                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 15))\n                    .select(bands) // 确保在过滤之前选择一致的波段集合\n                    .median();\n\nAdditionally, the code calculates the Normalized Difference Water Index (NDWI) and removes pixels from the composite image where the NDWI value is less than 0.3.\n\n  var ndwi = sentinel.normalizedDifference(['B3','B8']).rename('ndwi');\n  var image = sentinel.updateMask(ndwi.lt(0.3)).select(bands);\n  \n\n  Map.addLayer(image.clip(aoi), s_rgb, 'Sentinel ' + dateRange.year + '-' + dateRange.month);\n\nThis portion of the code loads a FeatureCollection of land types for a specific month. It specifies the dataset path for the specific month and stores it in the variable landTypes.\n\n  // 加载特定月份的FeatureCollection\n  var basePath = 'projects/ucfnqma/assets/Gaza/land_types_' + dateRange.pathSuffix;\n  var landTypes = ee.FeatureCollection(basePath);\n\nThe next segment of code is used to generate sample point collections for vegetation, bare soil, and urban classes respectively in Google Earth Engine. It adds a class label to each sample point to facilitate tasks such as land cover classification or supervised learning.\n\n  // 为每种landType生成样本点\n  var vegetationPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'vegetation')),\n    points: 3000 // 假设为植被类的数量\n  }).map(function(feat) { return feat.set('class', 0); });\n  \n  var barePoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'bare')),\n    points: 2000 // 假设为裸土类的数量\n  }).map(function(feat) { return feat.set('class', 1); });\n  \n  var urbanPoints = ee.FeatureCollection.randomPoints({\n    region: landTypes.filter(ee.Filter.eq('landType', 'urban')),\n    points: 1000 // 假设为城市类的数量\n  }).map(function(feat) { return feat.set('class', 2); });\n\nThis line of code merges three classes of sample point collections into one, and adds a random column to each sample point for subsequent operations such as image clipping.\n\n  // 合并所有样本点，并添加随机列以后续分割\n  var sample = vegetationPoints.merge(barePoints).merge(urbanPoints).randomColumn();\n\n\n\n\nIn this section we defined the split ratio using ‘var split = 0.7’.\n\n // Split sample set\n  var split = 0.7;\n  var training_sample = sample.filter(ee.Filter.lt('random', split));\n  var validation_sample = sample.filter(ee.Filter.gte('random', split));\nBased on the values of the random columns, 70% of the sample points are assigned to the verification set, and the remaining 30% are kept in the training set.\n\nBy extracting training set and validation set, the random forest model is initially fitted so that we train the model.\n\n  // take samples from image for training\n  var training = image.select(bands).sampleRegions({\n    collection: training_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n\n  // take samples from image for validation \n  var validation = image.select(bands).sampleRegions({\n    collection: validation_sample,\n    properties: ['class'],\n    scale: 10,\n  }).filter(ee.Filter.notNull(bands)); \n10.This section trains the model by fitting it with a training set and a validation set\n  // Trian the model\n var model = ee.Classifier.smileRandomForest(500).train({\n    features: training,\n    classProperty: 'class',\n    inputProperties: bands\n  });\n\n  // Calculate the confusion matrix for the training data\n  var trainAccuracy = training.classify(model).errorMatrix('class', 'classification');\n  print('Training error matrix: '+ dateRange.year + '-' + dateRange.month, trainAccuracy);\n  print('Training overall accuracy: '+ dateRange.year + '-' + dateRange.month, trainAccuracy.accuracy());\n\n  // Apply the RF classifier to the validation\n  var validated = validation.classify(model); // Fix using validation instead of validation_sample\n\n  // Calculate the confusion matrix for the validation data\n  var testAccuracy = validated.errorMatrix('class', 'classification');\n  print('Validation error matrix: '+ dateRange.year + '-' + dateRange.month, testAccuracy);\n  print('Validation overall accuracy: '+ dateRange.year + '-' + dateRange.month, testAccuracy.accuracy());\nThe function of the model is chosen such that we use ‘class’ read data for categorical prediction.\n11.After fitting the model, we use the overall image to classify the prediction using the dataset\n  var prediction = image.classify(model);\n\n  var landType_prediction = prediction.updateMask(prediction.neq(-1)); // Avoid using unclassified pixels\n  Map.addLayer(landType_prediction.clip(aoi), {min: 0, max: 2, palette: ['green', 'yellow', 'grey']}, 'LandType Prediction ' + dateRange.year + '-' + dateRange.month);\n\n});\n12.For a better view of the results, combine all results into one layer feature.\nvar vegetation = ee.FeatureCollection(vegetation.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'vegetation');\n}));\n\nvar urban = ee.FeatureCollection(urban.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'urban');\n}));\n\nvar bare = ee.FeatureCollection(bare.map(function(feature) {\n  return ee.Feature(feature).set('landType', 'bare');\n}));\n\n// 合并成一个FeatureCollection\nvar combinedFeatures = vegetation.merge(urban).merge(bare);\n\n\n\nExport.table.toAsset({\n  collection: combinedFeatures,\n  description: 'land_types_2022_11',\n  assetId: 'projects/ucfnqma/assets/Gaza/land_types_2022_11'});"
  },
  {
    "objectID": "index.html#interface-analysis-area-and-conduct-the-interface",
    "href": "index.html#interface-analysis-area-and-conduct-the-interface",
    "title": "CASA00025 Gaza",
    "section": "",
    "text": "Create a map instance and Set the center point and zoom level of the map\n\nvar map1 = ui.Map();\nmap1.centerObject(aoi,10.5);\n\nAdd a side UI, then create a selection box to place it in the side UI. Users can select 2022-11, 2022-12, 2023-1, 2023-2, 2023-11, 2023-12, 2024-1, 2024-2, 2024-3, and call a function to update the displayed layer.\n\nvar imageCollection = classificationCollection.map(function(img){\n  return img.clip(aoi);\n});\n// Create a selection box \nvar select = ui.Select({\n  items: ['2022-11', '2022-12', '2023-01', '2023-02', '2023-03','2023-11', '2023-12', '2024-01', '2024-02', '2024-03'],\n  value: '2022-11',  //Default selection '2022-11'\n  placeholder: 'Choose a number',\n  onChange: function(value) {\n    // Call the function to update the map\n    updateMaps(value);\n  }\n});\n\n// Create a label\nvar label = ui.Label('Please select a time', {margin: '10px 0px 5px 0px'});\n\n// Create a panel where you can place the selection boxes and labels\nvar controlPanel = ui.Panel({\n  widgets: [label, select],\n  style: {width: '300px', padding: '10px'} , // Positioning and styling\n  layout: ui.Panel.Layout.flow('horizontal')  // Set to horizontal layout\n});\n\n// Add the map to the root panel\nui.root.widgets().reset([map1]);\n\n// Set the style of the map\nmap1.style().set('width', '65%');\n\n// Create a panel to place the control panel\nvar sidebarPanel = ui.Panel({\n  widgets: [controlPanel],\n  style: {position: 'top-right', width: '120px',height: '300px',  margin: '0px 10px 0px 0px'}\n});\n\n// Adds the sidebar panel to the root panel\nui.root.add(sidebarPanel);\nThis is the detail of update function. In this function, we first converts a collection of images to a list, then determine the index of the image by month.\n// Converts a collection of images to a list\nvar imageList = imageCollection.toList(imageCollection.size());\n\nfunction updateMaps(month) {\n  // Determine the index of the image by month\n  var index1;\n  switch (month) {\n    case '2022-11':\n      index1 = 0;\n      break;\n    case '2022-12':\n      index1 = 1;\n      break;\n    case '2023-01':\n      index1 = 2;\n      break;\n    case '2023-02':\n      index1 = 3;\n      break;\n    case '2023-03':\n      index1 = 4;\n      break;\n    case '2023-11':\n      index1 = 5;\n      break;\n    case '2023-12':\n      index1 = 6;\n      break;\n    case '2024-01':\n      index1 = 7;\n      break;\n    case '2024-02':\n      index1 = 8;\n      break;\n    case '2024-03':\n      index1 = 9;\n      break;\n    default:\n      console.error('Invalid month selected:', month);\n      return;\n  }\n  // Get the image by index\n  var image1 = ee.Image(imageList.get(index1));\n\nAdd the legends to the map. We define the color list and description list, then create the legend style and legend panel. Add legend items in a loop. It contains description labels and color blocks, adds legend items to the inside version of the diagram, and adds legends to the lower left corner of the map.\n\npdateMaps('2022-11');\n\n// Define the color list and description list\nvar palette = ['green', 'yellow', 'grey']; // Suppose this is your list of colors\nvar names = ['vegetation', 'bare', 'urban']; // A description corresponding to the color\n\n// Create a style for the legend\nvar legendStyle = {\n  margin: '0px 8px 15px 0px',\n  padding: '0px 5px 5px 0px',\n  position: 'bottom-left'\n};\n\n// Create the panel of legend\nvar legendPanel = ui.Panel({\n  widgets: [], // Used to add legend entries\n  style: legendStyle\n});\n\n// Add a legend entry\nfor (var i = 0; i &lt; palette.length; i++) {\n  var legendItem = ui.Panel({\n    layout: ui.Panel.Layout.Flow('horizontal'),\n    style: {margin: '0px 10px'}\n  });\n  \n  // create color block\n  var colorBlock = ui.Label({\n    style: {\n      backgroundColor: palette[i],\n      padding: '5px',\n      margin: '0 0 4px 0'\n    }\n  });\n  \n  // create desctription label\n  var description = ui.Label({\n    value: names[i],\n    style: {margin: '0 0 4px 8px'}\n  });\n  \n  legendItem.add(colorBlock);\n  legendItem.add(description);\n  \n  // Adds a legend item to the Legend panel\n  legendPanel.add(legendItem);\n}\n\n// Add the legend to the bottom left corner of the map\nmap1.add(legendPanel);\n\nBefore drawing a line graph of vegetation area changes before and after conflicts, we need to export the image for area calculation. (Note: Due to the high computational complexity, calling the area calculation function directly can lead to long waiting times and may cause webpage crashes. Therefore, it is necessary to export the area calculation results first.)\n\n// Batch download functions\nfunction exportImage(image, roi, fileName) {  \n  Export.image.toAsset({  \n    image: image,\n    description: 'GAZA_'+fileName,\n    region: aoi,\n    scale: 10,\n    maxPixels: 1e13, // Maximum image element\n  });  \n}\n\n// Generate the list and download iteratively\nvar indexList = classificationCollection.reduceColumns(ee.Reducer.toList(), [\"system:index\"]).get(\"list\"); \nprint(\"indexList\", indexList);\nindexList.evaluate(function(indexs) { \n  for (var i=0; i&lt;indexs.length; i++) {  \n    var image = classificationCollection.filter(ee.Filter.eq(\"system:index\", indexs[i]))\n      .first()\n    var name=parseInt(indexs[i])\n        \n    exportImage(image, aoi, name);  //Save the image to Asset\n  }\n}); \n\nvar aoi = ee.FeatureCollection('users/liujingyue01/Gaza');\nvar imageCollection=ee.ImageCollection('projects/ee-guo112591/assets/GAZA');\n\n// Calculating the vegetation area as a function\nfunction calculateVegetationArea(image) {\n  var vegetationArea = image.select('classification').eq(0).multiply(ee.Image.pixelArea()).reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 30\n  }).get('classification');\n  return ee.Feature(null, {'date': image.get('date'), 'vegetationArea': vegetationArea});\n}\n\n// Apply a function to each Image in the imageCollection\nvar vegetationAreas = imageCollection.map(calculateVegetationArea).sort('date');\n\n// Convert the result to a list\nvar vegetationAreaList = vegetationAreas.toList(vegetationAreas.size());\nprint(vegetationAreaList)\nvar firstFive = ee.List.sequence(0, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n// var lastFive = ee.List.sequence(5, 9).map(function(i) { return ee.Feature(vegetationAreaList.get(i)).get('vegetationArea'); });\n\n// Convert the area to a numerical value\nvar firstFiveNumbers = firstFive.map(function(area) { return ee.Number(area); });\nprint(firstFiveNumbers)\n\nDraw the area calculation results onto a line graph. Set two y values before and after the conflict, which are two lines.\n\nvar firstFiveNumbers = ee.List([ 108.981451,\n  124.064503,\n  156.647346,\n  160.888861,\n  191.688693]);\nvar lastFiveNumbers = ee.List([145.504210,\n  160.795185,\n  125.786433,\n  105.063353, \n  107.703722]);\n\n// Abscissa data\nvar xAxis = ['11', '12', '1', '2', '3'];\n\n// Create a data source in the DataTable format that conforms to the Google Visualization API\nvar chartData = ee.FeatureCollection(xAxis.map(function(x, index) {\n  return ee.Feature(null, {\n    'x': x,\n    'y1': firstFiveNumbers.get(index),\n    'y2': lastFiveNumbers.get(index)\n  });\n}));\n\n// Create a line chart using ui.Chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2'] // Add two sets of y values\n}).setSeriesNames(['Before the conflict', 'After the conflict']) // Set series name\n  .setOptions({\n    title: 'Comparison of areas before and after the conflict',\n    hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n    vAxis: {title: 'vegetation Area', titleTextStyle: {color: 'blue'}},\n    legend: 'right' // Display legend\n  });\n\n// Set the size of the chart\nvar options = {\n  title: 'Comparison of areas before and after the conflict',\n  hAxis: {title: 'month', titleTextStyle: {color: 'red'}},\n  vAxis: {title: 'vegetation Area (km^2)', titleTextStyle: {color: 'blue'}},\n  legend: 'right',\n  width: 400, // Set chart width\n  height: 300 // Set chart height\n};\n\n// Create a line chart\nvar lineChart = ui.Chart.feature.byFeature({\n  features: chartData,\n  xProperty: 'x',\n  yProperties: ['y1', 'y2']\n}).setSeriesNames(['Before the cnflict', 'After the conflict']).setOptions(options);\n\n// Adjust the style of the sidebar panel to ensure that there is enough space to display the chart\nsidebarPanel.style().set({\n  width: '400px', // Sets the minimum width of the panel\n  height: 'auto' // Automatically adjust the height according to the content\n});\n\n// Adds a line chart to the sidebar panel\nsidebarPanel.add(lineChart);\n\nDraw a GIF image of post conflict land changes (November 2023.11-204.3) and place it in the side UI.\n\n//show gif\nfunction main() {\n  //Assume that the roi is defined and is a Feature or FeatureCollection\n  var roi = aoi;\n\n  // Let's say imgCol is defined and it contains 10 single-band images\n  var imgCol = classificationCollection.map(function(image){\n    return image.clip(roi);\n  });\n  \n  // Gets the number of images in the collection\n  var count =imgCol.toList(imgCol.size()).length();\n\n  // Calculate the number of images to skip\n  var skipCount = 5;\n\n  // Skip the previous images to get the last five images\n  var lastFiveImages = classificationCollection.toList(classificationCollection.size())\n  .slice(skipCount, count);\n\n  // Converts a list back to a collection of images\n  imgCol = ee.ImageCollection.fromImages(lastFiveImages).map(function(img){\n    return img.clip(aoi)\n  });\n\n  // Defines a function to map a single-band image to an RGB color\n  function mapToRgb(image) {\n    // Get a single band image\n    var band = image.select([0]);\n\n    // Creates a new image with the same R, G, and B values for each pixel\n    var r = band.where(band.eq(0), 0).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var g = band.where(band.eq(0), 128).where(band.eq(1), 255).where(band.eq(2), 200).toInt(); \n    var b = band.where(band.eq(0), 0).where(band.eq(1), 0).where(band.eq(2), 200).toInt();\n\n    // Returns a new image containing the RGB band\n    return ee.Image.cat(r, g, b).rename(['red', 'green', 'blue']).toFloat();\n  }\n\n  // Map each image to an RGB color\n  var rgbImgCol = imgCol.map(mapToRgb);\n\n  // GIF parameters\n  var params = {\n    crs: 'EPSG:3857',\n    framesPerSecond: 2,\n    region: roi.geometry().transform('EPSG:3857', 1), // Use the converted region\n    min: 0,\n    max: 255,\n    bands: ['red', 'green', 'blue'],\n    dimensions: 512,\n  };\n\n  // Add the GIF to the panel\n  sidebarPanel.add(ui.Thumbnail(rgbImgCol, params));\n  \n}\n\nmain();\n\nCreate a tag and set the tag’s hyperlink to download the GIF.\n\n// Create a label\nvar label = ui.Label('Download the GIF of \"Changing Land Conditions in Conflict\".');\n\n// Set the URL of the tag to make it a hyperlink\nlabel.setUrl(rgbImgCol.getVideoThumbURL(params));\n\nsidebarPanel.add(label);\nThe image output should look like this:\n\n\n\nChanging Land conditions in Conflict, 2023.11-2024.3"
  }
]